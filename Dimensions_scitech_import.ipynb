{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "##  Made by: Dr. Keungoui Kim\n",
    "##  Title: Scitech data import from Dimensions\n",
    "##  goal : \n",
    "##  Data set:  \n",
    "##  Time Span:\n",
    "##  Variables\n",
    "##      Input: \n",
    "##      Output: \n",
    "##  Time-stamp: #  \"Sun Jan 26 01:47:34 2020\":  edited by awe kim ; code\n",
    "##  Notice :\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "### Directory Setting for Export\n",
    "#dir = \"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/\" # Home\n",
    "dir = \"D:/Google Drive(awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/\" # HGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mDimcli - Dimensions API Client (v0.9.9.1)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl/v2> - DSL v2.5\u001b[0m\n",
      "\u001b[2mMethod: manual login\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### API log in\n",
    "import dimcli\n",
    "dimcli.login(key=\"792DDFAFCCA7478D8F37159F274A2783\",\n",
    "             endpoint=\"https://app.dimensions.ai/api/dsl/v2\")\n",
    "\n",
    "dsl = dimcli.Dsl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\n",
      "0-1000 / 12332 (10.04s)\n",
      "1000-2000 / 12332 (5.32s)\n",
      "2000-3000 / 12332 (4.10s)\n",
      "3000-4000 / 12332 (4.69s)\n",
      "4000-5000 / 12332 (4.85s)\n",
      "5000-6000 / 12332 (6.19s)\n",
      "6000-7000 / 12332 (4.84s)\n",
      "7000-8000 / 12332 (4.53s)\n",
      "8000-9000 / 12332 (4.95s)\n",
      "9000-10000 / 12332 (5.99s)\n",
      "10000-11000 / 12332 (8.05s)\n",
      "11000-12000 / 12332 (3.11s)\n",
      "12000-12332 / 12332 (2.19s)\n",
      "===\n",
      "Records extracted: 12332\n"
     ]
    }
   ],
   "source": [
    "### Extract patent data\n",
    "pat_data = dsl.query_iterative(\"\"\"search patents\n",
    "                                  where publications is not empty and year = 2022                    \n",
    "                                  return patents[id+year+priority_year+cpc+publications+publication_ids]\"\"\") #  limit 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12332, 6)\n",
      "12332\n"
     ]
    }
   ],
   "source": [
    "pat_data_df = pat_data.as_dataframe()\n",
    "print(pat_data_df.shape)\n",
    "print(pat_data_df.id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cpc</th>\n",
       "      <th>priority_year</th>\n",
       "      <th>publication_ids</th>\n",
       "      <th>publications</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>[A61K38/177, A61P29/00, C07K14/70578, A61P37/0...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1027342753, pub.1009940936]</td>\n",
       "      <td>[{'doi': '10.1182/blood-2003-06-2031', 'id': '...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO-2022236333-A2</td>\n",
       "      <td>[A61B3/0016, A61B3/0033]</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1065228315]</td>\n",
       "      <td>[{'doi': '10.1364/ol.35.000739', 'id': 'pub.10...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WO-2022236331-A1</td>\n",
       "      <td>[B05B12/18, B05B12/16, B05B14/00, B05B7/0408]</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1103595211]</td>\n",
       "      <td>[{'doi': '10.1002/adem.201701084', 'id': 'pub....</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO-2022236308-A1</td>\n",
       "      <td>[A61B5/0042, A61B34/30, G01R33/3806, G01R33/34...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1092392383]</td>\n",
       "      <td>[{'doi': '10.1109/tmag.2017.2751001', 'id': 'p...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO-2022236297-A1</td>\n",
       "      <td>[C11D3/48, C11D3/0068, C11D3/381, C11D7/40, C1...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1080312358]</td>\n",
       "      <td>[{'doi': '10.1128/jb.96.2.479-486.1968', 'id':...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                cpc  \\\n",
       "0  WO-2022236335-A1  [A61K38/177, A61P29/00, C07K14/70578, A61P37/0...   \n",
       "1  WO-2022236333-A2                           [A61B3/0016, A61B3/0033]   \n",
       "2  WO-2022236331-A1      [B05B12/18, B05B12/16, B05B14/00, B05B7/0408]   \n",
       "3  WO-2022236308-A1  [A61B5/0042, A61B34/30, G01R33/3806, G01R33/34...   \n",
       "4  WO-2022236297-A1  [C11D3/48, C11D3/0068, C11D3/381, C11D7/40, C1...   \n",
       "\n",
       "   priority_year                   publication_ids  \\\n",
       "0         2021.0  [pub.1027342753, pub.1009940936]   \n",
       "1         2021.0                  [pub.1065228315]   \n",
       "2         2021.0                  [pub.1103595211]   \n",
       "3         2021.0                  [pub.1092392383]   \n",
       "4         2021.0                  [pub.1080312358]   \n",
       "\n",
       "                                        publications  year  \n",
       "0  [{'doi': '10.1182/blood-2003-06-2031', 'id': '...  2022  \n",
       "1  [{'doi': '10.1364/ol.35.000739', 'id': 'pub.10...  2022  \n",
       "2  [{'doi': '10.1002/adem.201701084', 'id': 'pub....  2022  \n",
       "3  [{'doi': '10.1109/tmag.2017.2751001', 'id': 'p...  2022  \n",
       "4  [{'doi': '10.1128/jb.96.2.479-486.1968', 'id':...  2022  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_data_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+\"2022\"+\".csv\", index=False)\n",
    "pat_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import .csv files\n",
    "# pat_data_df = pd.read_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_01.csv\")\n",
    "\n",
    "# from ast import literal_eval\n",
    "\n",
    "# pat_data_df['publication_ids'] = pat_data_df['publication_ids'].apply(literal_eval) #convert to list type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>publication_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>pub.1027342753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>pub.1009940936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WO-2022236333-A2</td>\n",
       "      <td>pub.1065228315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO-2022236331-A1</td>\n",
       "      <td>pub.1103595211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO-2022236308-A1</td>\n",
       "      <td>pub.1092392383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id publication_ids\n",
       "0  WO-2022236335-A1  pub.1027342753\n",
       "1  WO-2022236335-A1  pub.1009940936\n",
       "2  WO-2022236333-A2  pub.1065228315\n",
       "3  WO-2022236331-A1  pub.1103595211\n",
       "4  WO-2022236308-A1  pub.1092392383"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_pub_df = pat_data_df[['id','publication_ids']]\n",
    "pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "pat_pub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract publication_ids\n",
    "pub_list = pat_pub_df.publication_ids.unique()\n",
    "pd.DataFrame(pub_list, columns=[\"publication_ids\"]).to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+\"2022\"+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalized Version\n",
    "- Maximum 50,000 records\n",
    "- dimcli query cannot recognize ''... so I had to write the loop for each jurisdiction --> fixed\n",
    "- If I could convert dataframe's column into a big list with \"\" as elements, I would use Version 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Codes for extracting patent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2000','2001','2002','2003','2004','2005','2006','2007','2008','2009', '2010', '2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] #, \n",
    "offices = ['EP'] # 'WO', 'US', 'EP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 2493 (2.05s)\u001b[0m\n",
      "1000-2000 / 2493 (2.00s)\u001b[0m\n",
      "2000-2493 / 2493 (1.49s)\u001b[0m\n",
      "===\n",
      "Records extracted: 2493\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 EP\n"
     ]
    }
   ],
   "source": [
    "### Create patent data.frame\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "        ### Patent set\n",
    "        query = \"\"\"search patents \n",
    "                    where publications is not empty and jurisdiction = \"\"\"+ '''\"'''+office+'''\"''' +\"\"\" and priority_year=\"\"\" + year + \"\"\" \n",
    "                    return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids+associated_grant_ids+funders] sort by priority_date\"\"\"\n",
    "        pat_data = dsl.query_iterative(query) \n",
    "        pat_df = pat_data.as_dataframe()\n",
    "\n",
    "        # Export patent set\n",
    "        pat_df.to_csv(dir+\"patent/pat_data_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "        \n",
    "        # Create cpc set\n",
    "        pat_cpc_df = pat_df[['id','cpc']]\n",
    "        pat_cpc_df = pat_cpc_df.explode(\"cpc\", ignore_index=True)\n",
    "        pat_cpc_df.to_csv(dir+\"patent/pat_cpc_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "\n",
    "        if 'associated_grant_ids' in pat_df.columns:\n",
    "            # Create patent grant set\n",
    "            pat_grant_list = pat_df[['id','associated_grant_ids']]\n",
    "            pat_grant_list = pat_grant_list.explode(\"associated_grant_ids\", ignore_index=True)\n",
    "            pat_grant_list.to_csv(dir+\"patent/pat_grant_list_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "        \n",
    "        if 'funders' in pat_df.columns:\n",
    "            # Create patent funders set (only select cases with funders)\n",
    "            pat_df = pat_df.dropna(subset=['funders'], how='any', axis=0)\n",
    "            pat_df.reset_index(drop=True, inplace=True)\n",
    "            pat_funders_df = pd.DataFrame()\n",
    "            for i in range(pat_df.shape[0]):\n",
    "                temp_data = pd.DataFrame.from_records(pat_df['funders'][i])\n",
    "                temp_data['id'] = pat_df['id'][i]\n",
    "                pat_funders_df = pd.concat([pat_funders_df, temp_data], axis=0)\n",
    "            pat_funders_df.to_csv(dir+\"patent/pat_funders_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "    \n",
    "    print(year, office)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Codes for extracting publication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 6576 (1.79s)\u001b[0m\n",
      "1000-2000 / 6576 (4.84s)\u001b[0m\n",
      "2000-3000 / 6576 (6.00s)\u001b[0m\n",
      "3000-4000 / 6576 (1.81s)\u001b[0m\n",
      "4000-5000 / 6576 (2.10s)\u001b[0m\n",
      "5000-6000 / 6576 (2.69s)\u001b[0m\n",
      "6000-6576 / 6576 (1.61s)\u001b[0m\n",
      "===\n",
      "Records extracted: 6576\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.60s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.25s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.62s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.82s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.84s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.66s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.77s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.72s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.89s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.64s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Create publication data.frame\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "        ### Patent set\n",
    "        query = \"\"\"search patents \n",
    "                    where publications is not empty and jurisdiction = \"\"\"+ '''\"'''+office+'''\"''' +\"\"\" and priority_year=\"\"\" + year + \"\"\" \n",
    "                    return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids+associated_grant_ids+funders] sort by priority_date\"\"\"\n",
    "        pat_data = dsl.query_iterative(query) \n",
    "        pat_df = pat_data.as_dataframe()\n",
    "\n",
    "        # Create publication set\n",
    "        pat_pub_df = pat_df[['id','publication_ids']]\n",
    "        pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "        pat_pub_df.to_csv(dir+\"pat_pub_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "\n",
    "        ## Export Publication List version 2. 50,000 each\n",
    "        pub_list = pat_pub_df.publication_ids.unique()\n",
    "        pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "        loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "        for i in range(1,loop):\n",
    "            temp = pub_list.iloc[0:49999,]\n",
    "            temp.to_csv(dir+\"publication/pub_list_\"+year+\"_\"+office+str(i)+\".csv\", index=False)\n",
    "\n",
    "            # in operator only can contain maximum 512 elements\n",
    "            # Thus, I run another loop for extracting 500 publication ids\n",
    "            inloop = math.ceil(temp.shape[0]/500)+1\n",
    "            pub_df = pd.DataFrame() # Create empty data.frame  \n",
    "            for j in range(1, inloop):\n",
    "                intemp = temp.iloc[0:499,]\n",
    "                query = \"\"\"search publications \n",
    "                        where id in \"\"\"+'''['''+','.join(f'\"{x}\"' for x in intemp['publication_ids'].to_list())+''']'''+\"\"\"\n",
    "                        return publications[id+type+volume+year+issue+title+journal+authors+category_for+supporting_grant_ids]\"\"\"\n",
    "                intemp_data = dsl.query_iterative(query)\n",
    "                intemp_data = intemp_data.as_dataframe()    \n",
    "                \n",
    "                pub_df = pd.concat([pub_df, intemp_data], axis=0, ignore_index=True)\n",
    "                temp = temp.drop(temp.index[0:499])          \n",
    "\n",
    "            # Rename pub_id\n",
    "            pub_df.rename(columns={'id':'pub_id'}, inplace=True)\n",
    "\n",
    "            if 'supporting_grant_ids' in pub_df.columns:\n",
    "                # Create publication grant set\n",
    "                pub_grant_list = pub_df[['pub_id','supporting_grant_ids']]\n",
    "                pub_grant_list = pub_grant_list.explode(\"supporting_grant_ids\", ignore_index=True)\n",
    "                pub_grant_list.to_csv(dir+\"publication/pub_grant_list_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "\n",
    "            if 'category_for' in pub_df.columns:\n",
    "                # Create publication category set\n",
    "                pub_category_df = pd.DataFrame()\n",
    "                for k in range(pub_df.shape[0]):\n",
    "                    if pd.isna(pub_df['category_for'])[k] == False:\n",
    "            #        if sum(pd.isna(pub_df['category_for'])[k]) != 0:\n",
    "                        temp_data = pd.DataFrame.from_records(pub_df['category_for'][k])\n",
    "                        temp_data['pub_id'] = pub_df['pub_id'][k]\n",
    "                        pub_category_df = pd.concat([pub_category_df, temp_data], axis=0, ignore_index=True)\n",
    "                        print(k)\n",
    "                pub_category_df.to_csv(dir+\"publication/pub_category_df_\"+year+\"_\"+office+\"_\"+str(i)+\".csv\", index=False)\n",
    "            \n",
    "            if 'authors' in pub_df.columns:\n",
    "                # Create authors set\n",
    "                pub_authors_df = pd.DataFrame()\n",
    "                for k in range(pub_df.shape[0]):\n",
    "                    if pd.isna(pub_df['authors'])[k] == False:\n",
    "#                    if sum(pd.isna(pub_df['authors'])[k]) != 0: # pd.isna(pub_df['authors'])[k] != True:\n",
    "                        temp_data = pd.DataFrame.from_records(pub_df['authors'][k])\n",
    "                        temp_data['pub_id'] = pub_df['pub_id'][k]\n",
    "                        pub_authors_df = pd.concat([pub_authors_df, temp_data], axis=0, ignore_index=True)\n",
    "                        print(k)\n",
    "                pub_authors_df.to_csv(dir+\"publication/pub_authors_df_\"+year+\"_\"+office+\"_\"+str(i)+\".csv\", index=False)\n",
    "\n",
    "                if 'affiliations' in pub_authors_df.columns:\n",
    "                    # Create affiliations set\n",
    "                    pub_affiliations_df = pd.DataFrame()\n",
    "                    for k in range(pub_authors_df.shape[0]):\n",
    "                        if pd.isna(pub_authors_df['affiliations'])[k] == False:\n",
    "    #                    if sum(pd.isna(pub_df['affiliations'])[k]) != 0: # pd.isna(pub_authors_df['affiliations'])[k] != True:\n",
    "                            temp_data = pd.DataFrame.from_records(pub_authors_df['affiliations'][k])\n",
    "                            temp_data['pub_id'] = pub_authors_df['pub_id'][k]\n",
    "                            pub_affiliations_df = pd.concat([pub_affiliations_df, temp_data], axis=0, ignore_index=True)\n",
    "                    pub_affiliations_df.to_csv(dir+\"publication/pub_affiliations_df_\"+year+\"_\"+office+\"_\"+str(i)+\".csv\", index=False)\n",
    "\n",
    "            # Save publication set\n",
    "            pub_df.to_csv(dir+\"publication/pub_data_df_\"+year+\"_\"+office+\"_\"+str(i)+\".csv\", index=False)\n",
    "            pub_list = pub_list.drop(pub_list.index[0:49999])          \n",
    "\n",
    "    print(year, office)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_id</th>\n",
       "      <th>supporting_grant_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pub.1008506950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pub.1030162990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pub.1037168643</td>\n",
       "      <td>grant.2519270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pub.1037168643</td>\n",
       "      <td>grant.2633999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pub.1037168643</td>\n",
       "      <td>grant.2683894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pub_id supporting_grant_ids\n",
       "0  pub.1008506950                  NaN\n",
       "1  pub.1030162990                  NaN\n",
       "2  pub.1037168643        grant.2519270\n",
       "3  pub.1037168643        grant.2633999\n",
       "4  pub.1037168643        grant.2683894"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_grant_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>pub_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80001</td>\n",
       "      <td>30 Agricultural, Veterinary and Food Sciences</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80029</td>\n",
       "      <td>3006 Food Sciences</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80001</td>\n",
       "      <td>30 Agricultural, Veterinary and Food Sciences</td>\n",
       "      <td>pub.1104426822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80029</td>\n",
       "      <td>3006 Food Sciences</td>\n",
       "      <td>pub.1104426822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80002</td>\n",
       "      <td>31 Biological Sciences</td>\n",
       "      <td>pub.1025486942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           name          pub_id\n",
       "0  80001  30 Agricultural, Veterinary and Food Sciences  pub.1125683875\n",
       "1  80029                             3006 Food Sciences  pub.1125683875\n",
       "2  80001  30 Agricultural, Veterinary and Food Sciences  pub.1104426822\n",
       "3  80029                             3006 Food Sciences  pub.1104426822\n",
       "4  80002                         31 Biological Sciences  pub.1025486942"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affiliations</th>\n",
       "      <th>corresponding</th>\n",
       "      <th>current_organization_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>orcid</th>\n",
       "      <th>raw_affiliation</th>\n",
       "      <th>researcher_id</th>\n",
       "      <th>pub_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'city': 'Multan', 'city_id': 1169825, 'count...</td>\n",
       "      <td>True</td>\n",
       "      <td>grid.413016.1</td>\n",
       "      <td>Haq</td>\n",
       "      <td>Nawaz</td>\n",
       "      <td>[0000-0001-8336-5280]</td>\n",
       "      <td>[Bahauddin Zakariya University, Department of ...</td>\n",
       "      <td>ur.012260462305.70</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'city': 'Multan', 'city_id': 1169825, 'count...</td>\n",
       "      <td></td>\n",
       "      <td>grid.411501.0</td>\n",
       "      <td>Muhammad Aslam</td>\n",
       "      <td>Shad</td>\n",
       "      <td>None</td>\n",
       "      <td>[Bahauddin Zakariya University, Department of ...</td>\n",
       "      <td>ur.015543155011.62</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'city': 'Multan', 'city_id': 1169825, 'count...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Najiha</td>\n",
       "      <td>Rehman</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Bahauddin Zakariya University, Institute of C...</td>\n",
       "      <td>None</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'city': 'Multan', 'city_id': 1169825, 'count...</td>\n",
       "      <td></td>\n",
       "      <td>grid.9026.d</td>\n",
       "      <td>Hina</td>\n",
       "      <td>Andaleeb</td>\n",
       "      <td>None</td>\n",
       "      <td>[Bahauddin Zakariya University, Department of ...</td>\n",
       "      <td>ur.012775222337.16</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'city': 'Multan', 'city_id': 1169825, 'count...</td>\n",
       "      <td></td>\n",
       "      <td>grid.411501.0</td>\n",
       "      <td>Najeeb</td>\n",
       "      <td>Ullah</td>\n",
       "      <td>[0000-0003-0900-5927]</td>\n",
       "      <td>[Bahauddin Zakariya University, Department of ...</td>\n",
       "      <td>ur.014426322101.31</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        affiliations corresponding  \\\n",
       "0  [{'city': 'Multan', 'city_id': 1169825, 'count...          True   \n",
       "1  [{'city': 'Multan', 'city_id': 1169825, 'count...                 \n",
       "2  [{'city': 'Multan', 'city_id': 1169825, 'count...                 \n",
       "3  [{'city': 'Multan', 'city_id': 1169825, 'count...                 \n",
       "4  [{'city': 'Multan', 'city_id': 1169825, 'count...                 \n",
       "\n",
       "  current_organization_id      first_name last_name                  orcid  \\\n",
       "0           grid.413016.1             Haq     Nawaz  [0000-0001-8336-5280]   \n",
       "1           grid.411501.0  Muhammad Aslam      Shad                   None   \n",
       "2                                  Najiha    Rehman                     []   \n",
       "3             grid.9026.d            Hina  Andaleeb                   None   \n",
       "4           grid.411501.0          Najeeb     Ullah  [0000-0003-0900-5927]   \n",
       "\n",
       "                                     raw_affiliation       researcher_id  \\\n",
       "0  [Bahauddin Zakariya University, Department of ...  ur.012260462305.70   \n",
       "1  [Bahauddin Zakariya University, Department of ...  ur.015543155011.62   \n",
       "2  [Bahauddin Zakariya University, Institute of C...                None   \n",
       "3  [Bahauddin Zakariya University, Department of ...  ur.012775222337.16   \n",
       "4  [Bahauddin Zakariya University, Department of ...  ur.014426322101.31   \n",
       "\n",
       "           pub_id  \n",
       "0  pub.1125683875  \n",
       "1  pub.1125683875  \n",
       "2  pub.1125683875  \n",
       "3  pub.1125683875  \n",
       "4  pub.1125683875  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_id</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>raw_affiliation</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>pub_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multan</td>\n",
       "      <td>1169825</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PK</td>\n",
       "      <td>grid.411501.0</td>\n",
       "      <td>Bahauddin Zakariya University</td>\n",
       "      <td>Bahauddin Zakariya University, Department of B...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multan</td>\n",
       "      <td>1169825</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PK</td>\n",
       "      <td>grid.411501.0</td>\n",
       "      <td>Bahauddin Zakariya University</td>\n",
       "      <td>Bahauddin Zakariya University, Department of B...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multan</td>\n",
       "      <td>1169825</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PK</td>\n",
       "      <td>grid.411501.0</td>\n",
       "      <td>Bahauddin Zakariya University</td>\n",
       "      <td>Bahauddin Zakariya University, Institute of Ch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multan</td>\n",
       "      <td>1169825</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PK</td>\n",
       "      <td>grid.411501.0</td>\n",
       "      <td>Bahauddin Zakariya University</td>\n",
       "      <td>Bahauddin Zakariya University, Department of B...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multan</td>\n",
       "      <td>1169825</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PK</td>\n",
       "      <td>grid.411501.0</td>\n",
       "      <td>Bahauddin Zakariya University</td>\n",
       "      <td>Bahauddin Zakariya University, Department of B...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pub.1125683875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city  city_id   country country_code             id  \\\n",
       "0  Multan  1169825  Pakistan           PK  grid.411501.0   \n",
       "1  Multan  1169825  Pakistan           PK  grid.411501.0   \n",
       "2  Multan  1169825  Pakistan           PK  grid.411501.0   \n",
       "3  Multan  1169825  Pakistan           PK  grid.411501.0   \n",
       "4  Multan  1169825  Pakistan           PK  grid.411501.0   \n",
       "\n",
       "                            name  \\\n",
       "0  Bahauddin Zakariya University   \n",
       "1  Bahauddin Zakariya University   \n",
       "2  Bahauddin Zakariya University   \n",
       "3  Bahauddin Zakariya University   \n",
       "4  Bahauddin Zakariya University   \n",
       "\n",
       "                                     raw_affiliation state state_code  \\\n",
       "0  Bahauddin Zakariya University, Department of B...  None       None   \n",
       "1  Bahauddin Zakariya University, Department of B...  None       None   \n",
       "2  Bahauddin Zakariya University, Institute of Ch...  None       None   \n",
       "3  Bahauddin Zakariya University, Department of B...  None       None   \n",
       "4  Bahauddin Zakariya University, Department of B...  None       None   \n",
       "\n",
       "           pub_id  \n",
       "0  pub.1125683875  \n",
       "1  pub.1125683875  \n",
       "2  pub.1125683875  \n",
       "3  pub.1125683875  \n",
       "4  pub.1125683875  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_affiliations_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create publication list\n",
    "years = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] \n",
    "offices = ['EP']\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "        # Create publication set\n",
    "        pat_pub_df = pat_df[['id','publication_ids']]\n",
    "        pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "        ## Export Publication List version 1. ALL\n",
    "        pub_list = pat_pub_df.publication_ids.unique()\n",
    "        pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "        pub_list.to_csv(dir+\"pub_list_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "\n",
    "        ## Export Publication List version 2. 50,000 each\n",
    "        pub_list = pat_pub_df.publication_ids.unique()\n",
    "        pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "        loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "        for i in range(1,loop):\n",
    "            temp = pub_list.iloc[0:49999,]\n",
    "            temp.to_csv(dir+\"pub_list_df_\"+year+\"_\"+office+str(i)+\".csv\", index=False)\n",
    "            pub_list = pub_list.drop(pub_list.index[0:49999])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create publication data.frame\n",
    "years = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] \n",
    "offices = ['EP']\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "        ### Publication set\n",
    "\n",
    "        ## Version 1. Request query for single publication id --> takes longer time\n",
    "        pub_list = pd.read_csv(dir+\"pub_list_df_\"+year+\"_\"+office+\".csv\")\n",
    "        # First record\n",
    "#        query = \"\"\"search publications \n",
    "#                    where id = \"\"\"+'''\"'''+pub_list.publication_ids[0]+'''\"'''+\"\"\"\n",
    "#                    return publications[id+type+volume+year+issue+title+journal+authors]\"\"\"\n",
    "#        temp_data = dsl.query(query)    \n",
    "#        pub_df = temp_data.as_dataframe()\n",
    "\n",
    "#        for pub in range(1,len(pub_list.publication_ids)):\n",
    "#            query = \"\"\"search publications \n",
    "#                        where id = \"\"\"+'''\"'''+pub_list.publication_ids[pub]+'''\"'''+\"\"\"\n",
    "#                        return publications[id+type+volume+year+issue+title+journal+authors+category_for]\"\"\"\n",
    "#            temp_data = dsl.query(query)    \n",
    "#            temp_data = temp_data.as_dataframe()\n",
    "#            \n",
    "#           # bind rows\n",
    "#           pub_df = pd.concat([pub_df, temp_data], axis=0)\n",
    "#\n",
    "#           print(year, office, pub)\n",
    "\n",
    "        # Version 2.\n",
    "        query = \"\"\"search publications \n",
    "                   where id in \"\"\"+'''['''+','.join(f'\"{x}\"' for x in pub_list['0'].to_list())+''']'''+\"\"\"\n",
    "                   return publications[id+type+volume+year+issue+title+journal+authors+category_for]\"\"\"\n",
    "        temp_data = dsl.query_iterative(query)\n",
    "        pub_df = temp_data.as_dataframe()    \n",
    "\n",
    "        # Save publication set\n",
    "        pub_df.to_csv(dir+\"pub_data_df_\"+year+\"_\"+office+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Publication list manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(dir+\"/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Total Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check total counts\n",
    "\n",
    "years = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] \n",
    "totalRecUS = []\n",
    "totalRecEU = []\n",
    "totalRecWO = []\n",
    "for year in years:\n",
    "    ### US\n",
    "    query = \"\"\"search patents \n",
    "                    where publications is not empty and jurisdiction in [\"US\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                    return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecUS.append(pat_data.count_total)\n",
    "\n",
    "    ### EP\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and jurisdiction in [\"EP\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "            return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecEUWO.append(pat_data.count_total)\n",
    "\n",
    "    ### WO\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and jurisdiction in [\"WO\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "            return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecEUWO.append(pat_data.count_total)\n",
    "\n",
    "    print(year)\n",
    "\n",
    "# Present result\n",
    "pd.DataFrame({'year':years,'USRec':totalRecUS,'EUWORec':totalRecEUWO})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = '2021'\n",
    "\n",
    "for year in years:\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and year=\"\"\" + year + \"\"\"\n",
    "            return patents[id+year+priority_year+cpc+publications+publication_ids]\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "    rangeIndex = int(temp.count_total/1000)+1\n",
    "\n",
    "    for t in range(50,rangeIndex):\n",
    "        query = \"\"\"search patents \n",
    "            where publications is not empty and year=\"\"\" + year + \"\"\"\n",
    "            return patents[id+year+priority_year+cpc+publications+publication_ids+reference_ids+times_cited] limit 1000 skip \"\"\" + str(1000*t)\n",
    "        temp_data = dsl.query(query)\n",
    "        temp_df = temp_data.as_dataframe()\n",
    "        # bind rows\n",
    "        pat_df = pd.concat([pat_df, temp_df], axis=0)\n",
    "        print(t)\n",
    "\n",
    "    # Save patent set\n",
    "    pat_data_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\".csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_data_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pd.DataFrame(pub_list, columns=[\"publication_ids\"]).to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%dslloop is a cell magic, but the cell body is empty. Did you mean the line magic %dslloop (single %)?\n"
     ]
    }
   ],
   "source": [
    "# %%dslloop my_data search publications for \"malaria\" return publications limit 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EP #####\n",
    "    query = \"\"\"search patents \n",
    "                where publications is not empty and jurisdiction in [\"EP\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "\n",
    "    # Save patent set\n",
    "    pat_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\"_EP.csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "\n",
    "    loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "    \n",
    "    for i in range(1,loop):\n",
    "        temp = pub_list.iloc[0:49999,]\n",
    "        temp.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\"_EP_\"+str(i)+\".csv\")\n",
    "        pub_list = pub_list.drop(pub_list.index[0:49999])\n",
    "\n",
    "    ##### WO #####\n",
    "    query = \"\"\"search patents \n",
    "                where publications is not empty and jurisdiction in [\"WO\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "\n",
    "    # Save patent set\n",
    "    pat_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\"_WO.csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "\n",
    "    loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "    \n",
    "    for i in range(1,loop):\n",
    "        temp = pub_list.iloc[0:49999,]\n",
    "        temp.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\"_WO_\"+str(i)+\".csv\")\n",
    "        pub_list = pub_list.drop(pub_list.index[0:49999])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
