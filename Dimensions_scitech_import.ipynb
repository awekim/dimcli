{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "##  Made by: Dr. Keungoui Kim\n",
    "##  Title: Scitech data import from Dimensions\n",
    "##  goal : \n",
    "##  Data set:  \n",
    "##  Time Span:\n",
    "##  Variables\n",
    "##      Input: \n",
    "##      Output: \n",
    "##  Time-stamp: #  \"Sun Jan 26 01:47:34 2020\":  edited by awe kim ; code\n",
    "##  Notice :\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Directory Setting for Export\n",
    "#dir = \"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/\" # Home\n",
    "dir = \"D:/Google Drive(awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/\" # HGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mDimcli - Dimensions API Client (v0.9.9.1)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl/v2> - DSL v2.5\u001b[0m\n",
      "\u001b[2mMethod: manual login\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Data Import\n",
    "import dimcli\n",
    "dimcli.login(key=\"792DDFAFCCA7478D8F37159F274A2783\",\n",
    "             endpoint=\"https://app.dimensions.ai/api/dsl/v2\")\n",
    "\n",
    "dsl = dimcli.Dsl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\n",
      "0-1000 / 12332 (10.04s)\n",
      "1000-2000 / 12332 (5.32s)\n",
      "2000-3000 / 12332 (4.10s)\n",
      "3000-4000 / 12332 (4.69s)\n",
      "4000-5000 / 12332 (4.85s)\n",
      "5000-6000 / 12332 (6.19s)\n",
      "6000-7000 / 12332 (4.84s)\n",
      "7000-8000 / 12332 (4.53s)\n",
      "8000-9000 / 12332 (4.95s)\n",
      "9000-10000 / 12332 (5.99s)\n",
      "10000-11000 / 12332 (8.05s)\n",
      "11000-12000 / 12332 (3.11s)\n",
      "12000-12332 / 12332 (2.19s)\n",
      "===\n",
      "Records extracted: 12332\n"
     ]
    }
   ],
   "source": [
    "### Extract patent data\n",
    "pat_data = dsl.query_iterative(\"\"\"search patents\n",
    "                                  where publications is not empty and year = 2022                    \n",
    "                                  return patents[id+year+priority_year+cpc+publications+publication_ids]\"\"\") #  limit 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12332, 6)\n",
      "12332\n"
     ]
    }
   ],
   "source": [
    "pat_data_df = pat_data.as_dataframe()\n",
    "print(pat_data_df.shape)\n",
    "print(pat_data_df.id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cpc</th>\n",
       "      <th>priority_year</th>\n",
       "      <th>publication_ids</th>\n",
       "      <th>publications</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>[A61K38/177, A61P29/00, C07K14/70578, A61P37/0...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1027342753, pub.1009940936]</td>\n",
       "      <td>[{'doi': '10.1182/blood-2003-06-2031', 'id': '...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO-2022236333-A2</td>\n",
       "      <td>[A61B3/0016, A61B3/0033]</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1065228315]</td>\n",
       "      <td>[{'doi': '10.1364/ol.35.000739', 'id': 'pub.10...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WO-2022236331-A1</td>\n",
       "      <td>[B05B12/18, B05B12/16, B05B14/00, B05B7/0408]</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1103595211]</td>\n",
       "      <td>[{'doi': '10.1002/adem.201701084', 'id': 'pub....</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO-2022236308-A1</td>\n",
       "      <td>[A61B5/0042, A61B34/30, G01R33/3806, G01R33/34...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1092392383]</td>\n",
       "      <td>[{'doi': '10.1109/tmag.2017.2751001', 'id': 'p...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO-2022236297-A1</td>\n",
       "      <td>[C11D3/48, C11D3/0068, C11D3/381, C11D7/40, C1...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1080312358]</td>\n",
       "      <td>[{'doi': '10.1128/jb.96.2.479-486.1968', 'id':...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                cpc  \\\n",
       "0  WO-2022236335-A1  [A61K38/177, A61P29/00, C07K14/70578, A61P37/0...   \n",
       "1  WO-2022236333-A2                           [A61B3/0016, A61B3/0033]   \n",
       "2  WO-2022236331-A1      [B05B12/18, B05B12/16, B05B14/00, B05B7/0408]   \n",
       "3  WO-2022236308-A1  [A61B5/0042, A61B34/30, G01R33/3806, G01R33/34...   \n",
       "4  WO-2022236297-A1  [C11D3/48, C11D3/0068, C11D3/381, C11D7/40, C1...   \n",
       "\n",
       "   priority_year                   publication_ids  \\\n",
       "0         2021.0  [pub.1027342753, pub.1009940936]   \n",
       "1         2021.0                  [pub.1065228315]   \n",
       "2         2021.0                  [pub.1103595211]   \n",
       "3         2021.0                  [pub.1092392383]   \n",
       "4         2021.0                  [pub.1080312358]   \n",
       "\n",
       "                                        publications  year  \n",
       "0  [{'doi': '10.1182/blood-2003-06-2031', 'id': '...  2022  \n",
       "1  [{'doi': '10.1364/ol.35.000739', 'id': 'pub.10...  2022  \n",
       "2  [{'doi': '10.1002/adem.201701084', 'id': 'pub....  2022  \n",
       "3  [{'doi': '10.1109/tmag.2017.2751001', 'id': 'p...  2022  \n",
       "4  [{'doi': '10.1128/jb.96.2.479-486.1968', 'id':...  2022  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_data_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+\"2022\"+\".csv\", index=False)\n",
    "pat_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import .csv files\n",
    "# pat_data_df = pd.read_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_01.csv\")\n",
    "\n",
    "# from ast import literal_eval\n",
    "\n",
    "# pat_data_df['publication_ids'] = pat_data_df['publication_ids'].apply(literal_eval) #convert to list type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>publication_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>pub.1027342753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>pub.1009940936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WO-2022236333-A2</td>\n",
       "      <td>pub.1065228315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO-2022236331-A1</td>\n",
       "      <td>pub.1103595211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO-2022236308-A1</td>\n",
       "      <td>pub.1092392383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id publication_ids\n",
       "0  WO-2022236335-A1  pub.1027342753\n",
       "1  WO-2022236335-A1  pub.1009940936\n",
       "2  WO-2022236333-A2  pub.1065228315\n",
       "3  WO-2022236331-A1  pub.1103595211\n",
       "4  WO-2022236308-A1  pub.1092392383"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_pub_df = pat_data_df[['id','publication_ids']]\n",
    "pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "pat_pub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract publication_ids\n",
    "pub_list = pat_pub_df.publication_ids.unique()\n",
    "pd.DataFrame(pub_list, columns=[\"publication_ids\"]).to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+\"2022\"+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalized Version\n",
    "- Maximum 50,000 records\n",
    "- dimcli query cannot recognize ''... so I had to write the loop for each jurisdiction --> fixed\n",
    "- If I could convert dataframe's column into a big list with \"\" as elements, I would use Version 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Codes for extracting patent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 6576 (5.62s)\u001b[0m\n",
      "1000-2000 / 6576 (2.35s)\u001b[0m\n",
      "2000-3000 / 6576 (2.08s)\u001b[0m\n",
      "3000-4000 / 6576 (2.02s)\u001b[0m\n",
      "4000-5000 / 6576 (5.91s)\u001b[0m\n",
      "5000-6000 / 6576 (11.77s)\u001b[0m\n",
      "6000-6576 / 6576 (1.90s)\u001b[0m\n",
      "===\n",
      "Records extracted: 6576\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 7872 (2.96s)\u001b[0m\n",
      "1000-2000 / 7872 (5.18s)\u001b[0m\n",
      "2000-3000 / 7872 (6.08s)\u001b[0m\n",
      "3000-4000 / 7872 (2.40s)\u001b[0m\n",
      "4000-5000 / 7872 (3.68s)\u001b[0m\n",
      "5000-6000 / 7872 (5.78s)\u001b[0m\n",
      "6000-7000 / 7872 (6.12s)\u001b[0m\n",
      "7000-7872 / 7872 (5.77s)\u001b[0m\n",
      "===\n",
      "Records extracted: 7872\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 8547 (3.06s)\u001b[0m\n",
      "1000-2000 / 8547 (2.31s)\u001b[0m\n",
      "2000-3000 / 8547 (3.10s)\u001b[0m\n",
      "3000-4000 / 8547 (2.12s)\u001b[0m\n",
      "4000-5000 / 8547 (6.04s)\u001b[0m\n",
      "5000-6000 / 8547 (2.24s)\u001b[0m\n",
      "6000-7000 / 8547 (3.75s)\u001b[0m\n",
      "7000-8000 / 8547 (2.16s)\u001b[0m\n",
      "8000-8547 / 8547 (3.81s)\u001b[0m\n",
      "===\n",
      "Records extracted: 8547\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 8934 (3.03s)\u001b[0m\n",
      "1000-2000 / 8934 (5.31s)\u001b[0m\n",
      "2000-3000 / 8934 (2.03s)\u001b[0m\n",
      "3000-4000 / 8934 (5.60s)\u001b[0m\n",
      "4000-5000 / 8934 (2.29s)\u001b[0m\n",
      "5000-6000 / 8934 (5.84s)\u001b[0m\n",
      "6000-7000 / 8934 (4.64s)\u001b[0m\n",
      "7000-8000 / 8934 (2.08s)\u001b[0m\n",
      "8000-8934 / 8934 (6.03s)\u001b[0m\n",
      "===\n",
      "Records extracted: 8934\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 10150 (2.81s)\u001b[0m\n",
      "1000-2000 / 10150 (5.52s)\u001b[0m\n",
      "2000-3000 / 10150 (2.16s)\u001b[0m\n",
      "3000-4000 / 10150 (3.60s)\u001b[0m\n",
      "4000-5000 / 10150 (2.41s)\u001b[0m\n",
      "5000-6000 / 10150 (3.61s)\u001b[0m\n",
      "6000-7000 / 10150 (6.31s)\u001b[0m\n",
      "7000-8000 / 10150 (5.70s)\u001b[0m\n",
      "8000-9000 / 10150 (2.29s)\u001b[0m\n",
      "9000-10000 / 10150 (2.03s)\u001b[0m\n",
      "10000-10150 / 10150 (5.63s)\u001b[0m\n",
      "===\n",
      "Records extracted: 10150\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 12615 (3.00s)\u001b[0m\n",
      "1000-2000 / 12615 (5.67s)\u001b[0m\n",
      "2000-3000 / 12615 (2.16s)\u001b[0m\n",
      "3000-4000 / 12615 (2.21s)\u001b[0m\n",
      "4000-5000 / 12615 (6.09s)\u001b[0m\n",
      "5000-6000 / 12615 (5.82s)\u001b[0m\n",
      "6000-7000 / 12615 (2.07s)\u001b[0m\n",
      "7000-8000 / 12615 (2.25s)\u001b[0m\n",
      "8000-9000 / 12615 (6.04s)\u001b[0m\n",
      "9000-10000 / 12615 (2.21s)\u001b[0m\n",
      "10000-11000 / 12615 (2.03s)\u001b[0m\n",
      "11000-12000 / 12615 (6.20s)\u001b[0m\n",
      "12000-12615 / 12615 (5.66s)\u001b[0m\n",
      "===\n",
      "Records extracted: 12615\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 14231 (3.49s)\u001b[0m\n",
      "1000-2000 / 14231 (2.82s)\u001b[0m\n",
      "2000-3000 / 14231 (2.69s)\u001b[0m\n",
      "3000-4000 / 14231 (6.02s)\u001b[0m\n",
      "4000-5000 / 14231 (2.23s)\u001b[0m\n",
      "5000-6000 / 14231 (2.27s)\u001b[0m\n",
      "6000-7000 / 14231 (6.04s)\u001b[0m\n",
      "7000-8000 / 14231 (5.98s)\u001b[0m\n",
      "8000-9000 / 14231 (2.27s)\u001b[0m\n",
      "9000-10000 / 14231 (5.83s)\u001b[0m\n",
      "10000-11000 / 14231 (11.13s)\u001b[0m\n",
      "11000-12000 / 14231 (2.20s)\u001b[0m\n",
      "12000-13000 / 14231 (2.19s)\u001b[0m\n",
      "13000-14000 / 14231 (6.02s)\u001b[0m\n",
      "14000-14231 / 14231 (1.74s)\u001b[0m\n",
      "===\n",
      "Records extracted: 14231\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 16209 (2.98s)\u001b[0m\n",
      "1000-2000 / 16209 (6.05s)\u001b[0m\n",
      "2000-3000 / 16209 (5.34s)\u001b[0m\n",
      "3000-4000 / 16209 (2.19s)\u001b[0m\n",
      "4000-5000 / 16209 (6.08s)\u001b[0m\n",
      "5000-6000 / 16209 (3.85s)\u001b[0m\n",
      "6000-7000 / 16209 (2.15s)\u001b[0m\n",
      "7000-8000 / 16209 (6.17s)\u001b[0m\n",
      "8000-9000 / 16209 (6.02s)\u001b[0m\n",
      "9000-10000 / 16209 (3.50s)\u001b[0m\n",
      "10000-11000 / 16209 (6.21s)\u001b[0m\n",
      "11000-12000 / 16209 (4.54s)\u001b[0m\n",
      "12000-13000 / 16209 (2.21s)\u001b[0m\n",
      "13000-14000 / 16209 (6.20s)\u001b[0m\n",
      "14000-15000 / 16209 (5.80s)\u001b[0m\n",
      "15000-16000 / 16209 (10.22s)\u001b[0m\n",
      "16000-16209 / 16209 (3.05s)\u001b[0m\n",
      "===\n",
      "Records extracted: 16209\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 16977 (2.85s)\u001b[0m\n",
      "1000-2000 / 16977 (3.01s)\u001b[0m\n",
      "2000-3000 / 16977 (11.32s)\u001b[0m\n",
      "3000-4000 / 16977 (2.20s)\u001b[0m\n",
      "4000-5000 / 16977 (2.30s)\u001b[0m\n",
      "5000-6000 / 16977 (6.81s)\u001b[0m\n",
      "6000-7000 / 16977 (2.19s)\u001b[0m\n",
      "7000-8000 / 16977 (6.72s)\u001b[0m\n",
      "8000-9000 / 16977 (5.36s)\u001b[0m\n",
      "9000-10000 / 16977 (5.92s)\u001b[0m\n",
      "10000-11000 / 16977 (6.17s)\u001b[0m\n",
      "11000-12000 / 16977 (6.48s)\u001b[0m\n",
      "12000-13000 / 16977 (2.38s)\u001b[0m\n",
      "13000-14000 / 16977 (2.41s)\u001b[0m\n",
      "14000-15000 / 16977 (5.85s)\u001b[0m\n",
      "15000-16000 / 16977 (6.14s)\u001b[0m\n",
      "16000-16977 / 16977 (2.30s)\u001b[0m\n",
      "===\n",
      "Records extracted: 16977\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 17902 (3.49s)\u001b[0m\n",
      "1000-2000 / 17902 (5.49s)\u001b[0m\n",
      "2000-3000 / 17902 (2.75s)\u001b[0m\n",
      "3000-4000 / 17902 (2.65s)\u001b[0m\n",
      "4000-5000 / 17902 (2.97s)\u001b[0m\n",
      "5000-6000 / 17902 (2.25s)\u001b[0m\n",
      "6000-7000 / 17902 (6.13s)\u001b[0m\n",
      "7000-8000 / 17902 (2.34s)\u001b[0m\n",
      "8000-9000 / 17902 (5.90s)\u001b[0m\n",
      "9000-10000 / 17902 (7.87s)\u001b[0m\n",
      "10000-11000 / 17902 (4.29s)\u001b[0m\n",
      "11000-12000 / 17902 (2.39s)\u001b[0m\n",
      "12000-13000 / 17902 (2.33s)\u001b[0m\n",
      "13000-14000 / 17902 (6.11s)\u001b[0m\n",
      "14000-15000 / 17902 (6.00s)\u001b[0m\n",
      "15000-16000 / 17902 (5.91s)\u001b[0m\n",
      "16000-17000 / 17902 (2.37s)\u001b[0m\n",
      "17000-17902 / 17902 (3.76s)\u001b[0m\n",
      "===\n",
      "Records extracted: 17902\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Create patent data.frame\n",
    "years = ['2000','2001','2002','2003','2004','2005','2006','2007','2008','2009'] #'2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'\n",
    "offices = ['EP'] # 'WO', 'US', 'EP'\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "        ### Patent set\n",
    "        query = \"\"\"search patents \n",
    "                    where publications is not empty and jurisdiction = \"\"\"+ '''\"'''+office+'''\"''' +\"\"\" and priority_year=\"\"\" + year + \"\"\" \n",
    "                    return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "        pat_data = dsl.query_iterative(query) \n",
    "        pat_df = pat_data.as_dataframe()\n",
    "\n",
    "        # Export patent set\n",
    "        pat_df.to_csv(dir+\"pat_data_df_\"+year+\"_\"+office+\".csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Codes for extracting publication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 6576 (2.05s)\u001b[0m\n",
      "1000-2000 / 6576 (1.97s)\u001b[0m\n",
      "2000-3000 / 6576 (4.56s)\u001b[0m\n",
      "3000-4000 / 6576 (1.88s)\u001b[0m\n",
      "4000-5000 / 6576 (4.55s)\u001b[0m\n",
      "5000-6000 / 6576 (1.96s)\u001b[0m\n",
      "6000-6576 / 6576 (1.55s)\u001b[0m\n",
      "===\n",
      "Records extracted: 6576\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.81s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.76s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.50s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.32s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.27s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.11s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.92s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.12s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.49s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.79s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.92s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.53s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.59s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.86s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.07s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.01s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.25s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.54s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-292 / 292 (2.96s)\u001b[0m\n",
      "===\n",
      "Records extracted: 292\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 EP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-1000 / 7872 (2.28s)\u001b[0m\n",
      "1000-2000 / 7872 (5.87s)\u001b[0m\n",
      "2000-3000 / 7872 (3.55s)\u001b[0m\n",
      "3000-4000 / 7872 (5.59s)\u001b[0m\n",
      "4000-5000 / 7872 (1.98s)\u001b[0m\n",
      "5000-6000 / 7872 (2.64s)\u001b[0m\n",
      "6000-7000 / 7872 (6.06s)\u001b[0m\n",
      "7000-7872 / 7872 (7.24s)\u001b[0m\n",
      "===\n",
      "Records extracted: 7872\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.00s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.54s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.71s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.29s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.09s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.48s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.28s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.16s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.20s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.34s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.36s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.20s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.51s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.15s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.33s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.40s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.49s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.17s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.15s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (7.34s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.66s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-173 / 173 (5.24s)\u001b[0m\n",
      "===\n",
      "Records extracted: 173\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 EP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-1000 / 8547 (1.94s)\u001b[0m\n",
      "1000-2000 / 8547 (4.52s)\u001b[0m\n",
      "2000-3000 / 8547 (5.81s)\u001b[0m\n",
      "3000-4000 / 8547 (2.13s)\u001b[0m\n",
      "4000-5000 / 8547 (4.36s)\u001b[0m\n",
      "5000-6000 / 8547 (5.88s)\u001b[0m\n",
      "6000-7000 / 8547 (6.18s)\u001b[0m\n",
      "7000-8000 / 8547 (2.07s)\u001b[0m\n",
      "8000-8547 / 8547 (1.87s)\u001b[0m\n",
      "===\n",
      "Records extracted: 8547\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.72s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.13s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.72s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.43s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.19s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (7.63s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.21s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.78s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.09s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.09s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.81s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.31s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.06s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.79s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.04s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.33s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.18s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.32s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.81s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-498 / 498 (2.39s)\u001b[0m\n",
      "===\n",
      "Records extracted: 498\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.40s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.73s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.23s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.64s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.87s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.77s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.68s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-310 / 310 (5.70s)\u001b[0m\n",
      "===\n",
      "Records extracted: 310\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002 EP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-1000 / 8934 (1.84s)\u001b[0m\n",
      "1000-2000 / 8934 (2.23s)\u001b[0m\n",
      "2000-3000 / 8934 (1.90s)\u001b[0m\n",
      "3000-4000 / 8934 (2.47s)\u001b[0m\n",
      "4000-5000 / 8934 (1.94s)\u001b[0m\n",
      "5000-6000 / 8934 (2.35s)\u001b[0m\n",
      "6000-7000 / 8934 (2.09s)\u001b[0m\n",
      "7000-8000 / 8934 (1.84s)\u001b[0m\n",
      "8000-8934 / 8934 (4.98s)\u001b[0m\n",
      "===\n",
      "Records extracted: 8934\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.01s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.39s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.73s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.96s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.11s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.30s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.98s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.99s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.92s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.33s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.86s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-498 / 498 (2.90s)\u001b[0m\n",
      "===\n",
      "Records extracted: 498\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.21s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.95s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.90s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.11s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.06s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.06s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.19s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.93s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.09s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.75s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.09s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.75s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.43s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.33s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.72s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.90s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-225 / 225 (2.65s)\u001b[0m\n",
      "===\n",
      "Records extracted: 225\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003 EP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-1000 / 10150 (1.77s)\u001b[0m\n",
      "1000-2000 / 10150 (1.75s)\u001b[0m\n",
      "2000-3000 / 10150 (1.97s)\u001b[0m\n",
      "3000-4000 / 10150 (3.24s)\u001b[0m\n",
      "4000-5000 / 10150 (1.95s)\u001b[0m\n",
      "5000-6000 / 10150 (1.84s)\u001b[0m\n",
      "6000-7000 / 10150 (1.92s)\u001b[0m\n",
      "7000-8000 / 10150 (7.15s)\u001b[0m\n",
      "8000-9000 / 10150 (1.97s)\u001b[0m\n",
      "9000-10000 / 10150 (1.93s)\u001b[0m\n",
      "10000-10150 / 10150 (1.73s)\u001b[0m\n",
      "===\n",
      "Records extracted: 10150\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.43s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.76s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.87s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.49s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.38s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.27s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.56s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.25s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.88s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.11s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.79s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.06s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.07s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.02s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.02s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.50s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.50s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.84s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.10s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.54s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.40s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.58s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.84s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.14s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.40s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.98s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.65s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.75s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.29s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.01s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.20s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.27s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.37s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.81s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-38 / 38 (5.29s)\u001b[0m\n",
      "===\n",
      "Records extracted: 38\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004 EP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-1000 / 12615 (2.18s)\u001b[0m\n",
      "1000-2000 / 12615 (9.31s)\u001b[0m\n",
      "2000-3000 / 12615 (1.99s)\u001b[0m\n",
      "3000-4000 / 12615 (4.91s)\u001b[0m\n",
      "4000-5000 / 12615 (5.79s)\u001b[0m\n",
      "5000-6000 / 12615 (5.91s)\u001b[0m\n",
      "6000-7000 / 12615 (6.06s)\u001b[0m\n",
      "7000-8000 / 12615 (6.45s)\u001b[0m\n",
      "8000-9000 / 12615 (5.96s)\u001b[0m\n",
      "9000-10000 / 12615 (6.96s)\u001b[0m\n",
      "10000-11000 / 12615 (2.00s)\u001b[0m\n",
      "11000-12000 / 12615 (2.02s)\u001b[0m\n",
      "12000-12615 / 12615 (5.88s)\u001b[0m\n",
      "===\n",
      "Records extracted: 12615\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.43s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-498 / 498 (4.89s)\u001b[0m\n",
      "===\n",
      "Records extracted: 498\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.30s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.16s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.99s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.26s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.00s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.19s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.13s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.80s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.45s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.85s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.18s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.53s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.17s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.03s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.64s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.08s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.04s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.93s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.79s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.69s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.14s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.71s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.27s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.04s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.15s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.05s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.64s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.61s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.99s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.48s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.93s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.35s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.14s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.08s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.97s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.10s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.15s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.06s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.99s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-237 / 237 (2.61s)\u001b[0m\n",
      "===\n",
      "Records extracted: 237\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005 EP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-1000 / 14231 (1.98s)\u001b[0m\n",
      "1000-2000 / 14231 (4.33s)\u001b[0m\n",
      "2000-3000 / 14231 (1.81s)\u001b[0m\n",
      "3000-4000 / 14231 (4.61s)\u001b[0m\n",
      "4000-5000 / 14231 (2.02s)\u001b[0m\n",
      "5000-6000 / 14231 (1.87s)\u001b[0m\n",
      "6000-7000 / 14231 (4.50s)\u001b[0m\n",
      "7000-8000 / 14231 (1.85s)\u001b[0m\n",
      "8000-9000 / 14231 (1.79s)\u001b[0m\n",
      "9000-10000 / 14231 (1.94s)\u001b[0m\n",
      "10000-11000 / 14231 (1.91s)\u001b[0m\n",
      "11000-12000 / 14231 (4.42s)\u001b[0m\n",
      "12000-13000 / 14231 (1.88s)\u001b[0m\n",
      "13000-14000 / 14231 (1.72s)\u001b[0m\n",
      "14000-14231 / 14231 (4.24s)\u001b[0m\n",
      "===\n",
      "Records extracted: 14231\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (8.17s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.80s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.66s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.73s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.56s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.61s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.58s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.35s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.19s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.98s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.83s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.79s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.10s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.83s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.75s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.28s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.73s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.28s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.89s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.58s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.75s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.01s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.11s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.58s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.72s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.37s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.75s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.47s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.18s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.54s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.41s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.64s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.12s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.96s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.18s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.59s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.92s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.53s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.61s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.18s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.71s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.08s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.07s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-132 / 132 (1.80s)\u001b[0m\n",
      "===\n",
      "Records extracted: 132\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006 EP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-1000 / 16209 (1.80s)\u001b[0m\n",
      "1000-2000 / 16209 (1.83s)\u001b[0m\n",
      "2000-3000 / 16209 (2.02s)\u001b[0m\n",
      "3000-4000 / 16209 (2.53s)\u001b[0m\n",
      "4000-5000 / 16209 (3.40s)\u001b[0m\n",
      "5000-6000 / 16209 (2.65s)\u001b[0m\n",
      "6000-7000 / 16209 (2.35s)\u001b[0m\n",
      "7000-8000 / 16209 (4.42s)\u001b[0m\n",
      "8000-9000 / 16209 (2.19s)\u001b[0m\n",
      "9000-10000 / 16209 (5.77s)\u001b[0m\n",
      "10000-11000 / 16209 (2.05s)\u001b[0m\n",
      "11000-12000 / 16209 (6.17s)\u001b[0m\n",
      "12000-13000 / 16209 (2.06s)\u001b[0m\n",
      "13000-14000 / 16209 (7.08s)\u001b[0m\n",
      "14000-15000 / 16209 (1.96s)\u001b[0m\n",
      "15000-16000 / 16209 (2.98s)\u001b[0m\n",
      "16000-16209 / 16209 (4.38s)\u001b[0m\n",
      "===\n",
      "Records extracted: 16209\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (8.42s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.59s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.87s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.95s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.20s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.64s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.49s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.46s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.91s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (5.81s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.14s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.04s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.66s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.20s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.23s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.02s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.85s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.98s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.86s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.62s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.11s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.25s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.31s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.54s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.28s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.08s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.11s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.48s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.20s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.31s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.98s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.15s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (4.14s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (6.29s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.60s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (2.90s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-499 / 499 (3.00s)\u001b[0m\n",
      "===\n",
      "Records extracted: 499\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "502 Server Error: Bad Gateway for url: https://app.dimensions.ai/api/dsl/v2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\내 드라이브\\[git]\\dimcli\\Dimensions_scitech_import.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/%5Bgit%5D/dimcli/Dimensions_scitech_import.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m intemp \u001b[39m=\u001b[39m temp\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m:\u001b[39m499\u001b[39m,]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/%5Bgit%5D/dimcli/Dimensions_scitech_import.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39msearch publications \u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/%5Bgit%5D/dimcli/Dimensions_scitech_import.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m        where id in \u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'''\u001b[39m\u001b[39m[\u001b[39m\u001b[39m'''\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m intemp[\u001b[39m'\u001b[39m\u001b[39mpublication_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list())\u001b[39m+\u001b[39m\u001b[39m'''\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'''\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/%5Bgit%5D/dimcli/Dimensions_scitech_import.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m        return publications[id+type+volume+year+issue+title+journal+authors+category_for]\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/%5Bgit%5D/dimcli/Dimensions_scitech_import.ipynb#X20sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m intemp_data \u001b[39m=\u001b[39m dsl\u001b[39m.\u001b[39;49mquery_iterative(query)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/%5Bgit%5D/dimcli/Dimensions_scitech_import.ipynb#X20sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m intemp_data \u001b[39m=\u001b[39m intemp_data\u001b[39m.\u001b[39mas_dataframe()    \n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/%5Bgit%5D/dimcli/Dimensions_scitech_import.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m pub_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pub_df, intemp_data], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\dimcli\\core\\api.py:292\u001b[0m, in \u001b[0;36mDsl.query_iterative\u001b[1;34m(self, q, show_results, limit, skip, pause, force, maxlimit, verbose, _tot_count_prev_query, _warnings_tot)\u001b[0m\n\u001b[0;32m    289\u001b[0m q2 \u001b[39m=\u001b[39m q \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m limit \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m skip \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (limit, skip)\n\u001b[0;32m    291\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 292\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery(q2, show_results\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, retry\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    293\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    294\u001b[0m elapsed \u001b[39m=\u001b[39m end \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\dimcli\\core\\api.py:196\u001b[0m, in \u001b[0;36mDsl.query\u001b[1;34m(self, q, show_results, retry, verbose)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mif\u001b[39;00m verbose: printDebug(\u001b[39m\"\u001b[39m\u001b[39mResponse.header\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m---\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(response\u001b[39m.\u001b[39mheaders), \u001b[39m\"\u001b[39m\u001b[39mred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m verbose: printDebug(\u001b[39m\"\u001b[39m\u001b[39mResponse.content\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m---\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(response\u001b[39m.\u001b[39mcontent), \u001b[39m\"\u001b[39m\u001b[39mred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m response\u001b[39m.\u001b[39;49mraise_for_status()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\requests\\models.py:960\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    957\u001b[0m     http_error_msg \u001b[39m=\u001b[39m \u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code, reason, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl)\n\u001b[0;32m    959\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[1;32m--> 960\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 502 Server Error: Bad Gateway for url: https://app.dimensions.ai/api/dsl/v2"
     ]
    }
   ],
   "source": [
    "### Create patent data.frame\n",
    "# 230102 - 2006 \n",
    "years = ['2000','2001','2002','2003','2004','2005','2006','2007','2008','2009'] #'2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'\n",
    "offices = ['EP']\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "        ### Patent set\n",
    "        query = \"\"\"search patents \n",
    "                    where publications is not empty and jurisdiction = \"\"\"+ '''\"'''+office+'''\"''' +\"\"\" and priority_year=\"\"\" + year + \"\"\" \n",
    "                    return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "        pat_data = dsl.query_iterative(query) \n",
    "        pat_df = pat_data.as_dataframe()\n",
    "\n",
    "        # Export patent set\n",
    "        pat_df.to_csv(dir+\"pat_data_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "\n",
    "        # Create publication set\n",
    "        pat_pub_df = pat_df[['id','publication_ids']]\n",
    "        pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "        ## Export Publication List version 2. 50,000 each\n",
    "        pub_list = pat_pub_df.publication_ids.unique()\n",
    "        pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "        loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "        for i in range(1,loop):\n",
    "            temp = pub_list.iloc[0:49999,]\n",
    "            temp.to_csv(dir+\"pub_list_df_\"+year+\"_\"+office+str(i)+\".csv\", index=False)\n",
    "\n",
    "            # in operator only can contain maximum 512 elements\n",
    "            # Thus, I run another loop for extracting 500 publication ids\n",
    "            inloop = math.ceil(temp.shape[0]/500)+1\n",
    "            pub_df = pd.DataFrame() # Create empty data.frame  \n",
    "            for j in range(1, inloop):\n",
    "                intemp = temp.iloc[0:499,]\n",
    "                query = \"\"\"search publications \n",
    "                        where id in \"\"\"+'''['''+','.join(f'\"{x}\"' for x in intemp['publication_ids'].to_list())+''']'''+\"\"\"\n",
    "                        return publications[id+type+volume+year+issue+title+journal+authors+category_for]\"\"\"\n",
    "                intemp_data = dsl.query_iterative(query)\n",
    "                intemp_data = intemp_data.as_dataframe()    \n",
    "                \n",
    "                pub_df = pd.concat([pub_df, intemp_data], axis=0)\n",
    "                temp = temp.drop(temp.index[0:499])          \n",
    "\n",
    "\n",
    "            # Save publication set\n",
    "            pub_df.to_csv(dir+\"pub_data_df_\"+year+\"_\"+office+\"_\"+str(i)+\".csv\", index=False)\n",
    "            pub_list = pub_list.drop(pub_list.index[0:49999])          \n",
    "\n",
    "    print(year, office)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create publication list\n",
    "years = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] \n",
    "offices = ['EP']\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "        # Create publication set\n",
    "        pat_pub_df = pat_df[['id','publication_ids']]\n",
    "        pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "        ## Export Publication List version 1. ALL\n",
    "        pub_list = pat_pub_df.publication_ids.unique()\n",
    "        pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "        pub_list.to_csv(dir+\"pub_list_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "\n",
    "        ## Export Publication List version 2. 50,000 each\n",
    "        pub_list = pat_pub_df.publication_ids.unique()\n",
    "        pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "        loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "        for i in range(1,loop):\n",
    "            temp = pub_list.iloc[0:49999,]\n",
    "            temp.to_csv(dir+\"pub_list_df_\"+year+\"_\"+office+str(i)+\".csv\", index=False)\n",
    "            pub_list = pub_list.drop(pub_list.index[0:49999])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create publication data.frame\n",
    "years = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] \n",
    "offices = ['EP']\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "        ### Publication set\n",
    "\n",
    "        ## Version 1. Request query for single publication id --> takes longer time\n",
    "        pub_list = pd.read_csv(dir+\"pub_list_df_\"+year+\"_\"+office+\".csv\")\n",
    "        # First record\n",
    "#        query = \"\"\"search publications \n",
    "#                    where id = \"\"\"+'''\"'''+pub_list.publication_ids[0]+'''\"'''+\"\"\"\n",
    "#                    return publications[id+type+volume+year+issue+title+journal+authors]\"\"\"\n",
    "#        temp_data = dsl.query(query)    \n",
    "#        pub_df = temp_data.as_dataframe()\n",
    "\n",
    "#        for pub in range(1,len(pub_list.publication_ids)):\n",
    "#            query = \"\"\"search publications \n",
    "#                        where id = \"\"\"+'''\"'''+pub_list.publication_ids[pub]+'''\"'''+\"\"\"\n",
    "#                        return publications[id+type+volume+year+issue+title+journal+authors+category_for]\"\"\"\n",
    "#            temp_data = dsl.query(query)    \n",
    "#            temp_data = temp_data.as_dataframe()\n",
    "#            \n",
    "#           # bind rows\n",
    "#           pub_df = pd.concat([pub_df, temp_data], axis=0)\n",
    "#\n",
    "#           print(year, office, pub)\n",
    "\n",
    "        # Version 2.\n",
    "        query = \"\"\"search publications \n",
    "                   where id in \"\"\"+'''['''+','.join(f'\"{x}\"' for x in pub_list['0'].to_list())+''']'''+\"\"\"\n",
    "                   return publications[id+type+volume+year+issue+title+journal+authors+category_for]\"\"\"\n",
    "        temp_data = dsl.query_iterative(query)\n",
    "        pub_df = temp_data.as_dataframe()    \n",
    "\n",
    "        # Save publication set\n",
    "        pub_df.to_csv(dir+\"pub_data_df_\"+year+\"_\"+office+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Publication list manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(dir+\"/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Total Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check total counts\n",
    "\n",
    "years = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] \n",
    "totalRecUS = []\n",
    "totalRecEU = []\n",
    "totalRecWO = []\n",
    "for year in years:\n",
    "    ### US\n",
    "    query = \"\"\"search patents \n",
    "                    where publications is not empty and jurisdiction in [\"US\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                    return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecUS.append(pat_data.count_total)\n",
    "\n",
    "    ### EP\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and jurisdiction in [\"EP\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "            return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecEUWO.append(pat_data.count_total)\n",
    "\n",
    "    ### WO\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and jurisdiction in [\"WO\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "            return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecEUWO.append(pat_data.count_total)\n",
    "\n",
    "    print(year)\n",
    "\n",
    "# Present result\n",
    "pd.DataFrame({'year':years,'USRec':totalRecUS,'EUWORec':totalRecEUWO})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = '2021'\n",
    "\n",
    "for year in years:\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and year=\"\"\" + year + \"\"\"\n",
    "            return patents[id+year+priority_year+cpc+publications+publication_ids]\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "    rangeIndex = int(temp.count_total/1000)+1\n",
    "\n",
    "    for t in range(50,rangeIndex):\n",
    "        query = \"\"\"search patents \n",
    "            where publications is not empty and year=\"\"\" + year + \"\"\"\n",
    "            return patents[id+year+priority_year+cpc+publications+publication_ids+reference_ids+times_cited] limit 1000 skip \"\"\" + str(1000*t)\n",
    "        temp_data = dsl.query(query)\n",
    "        temp_df = temp_data.as_dataframe()\n",
    "        # bind rows\n",
    "        pat_df = pd.concat([pat_df, temp_df], axis=0)\n",
    "        print(t)\n",
    "\n",
    "    # Save patent set\n",
    "    pat_data_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\".csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_data_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pd.DataFrame(pub_list, columns=[\"publication_ids\"]).to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%dslloop is a cell magic, but the cell body is empty. Did you mean the line magic %dslloop (single %)?\n"
     ]
    }
   ],
   "source": [
    "# %%dslloop my_data search publications for \"malaria\" return publications limit 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EP #####\n",
    "    query = \"\"\"search patents \n",
    "                where publications is not empty and jurisdiction in [\"EP\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "\n",
    "    # Save patent set\n",
    "    pat_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\"_EP.csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "\n",
    "    loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "    \n",
    "    for i in range(1,loop):\n",
    "        temp = pub_list.iloc[0:49999,]\n",
    "        temp.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\"_EP_\"+str(i)+\".csv\")\n",
    "        pub_list = pub_list.drop(pub_list.index[0:49999])\n",
    "\n",
    "    ##### WO #####\n",
    "    query = \"\"\"search patents \n",
    "                where publications is not empty and jurisdiction in [\"WO\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "\n",
    "    # Save patent set\n",
    "    pat_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\"_WO.csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "\n",
    "    loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "    \n",
    "    for i in range(1,loop):\n",
    "        temp = pub_list.iloc[0:49999,]\n",
    "        temp.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\"_WO_\"+str(i)+\".csv\")\n",
    "        pub_list = pub_list.drop(pub_list.index[0:49999])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
