{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "##  Made by: Dr. Keungoui Kim\n",
    "##  Title: Scitech data import from Dimensions\n",
    "##  goal : \n",
    "##  Data set:  \n",
    "##  Time Span:\n",
    "##  Variables\n",
    "##      Input: \n",
    "##      Output: \n",
    "##  Time-stamp: #  \"Sun Jan 26 01:47:34 2020\":  edited by awe kim ; code\n",
    "##  Notice :\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Directory Setting for Export\n",
    "dir = \"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/\" # Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimcli - Dimensions API Client (v0.9.9.1)\n",
      "Connected to: <https://app.dimensions.ai/api/dsl/v2> - DSL v2.5\n",
      "Method: manual login\n"
     ]
    }
   ],
   "source": [
    "### Data Import\n",
    "import dimcli\n",
    "dimcli.login(key=\"792DDFAFCCA7478D8F37159F274A2783\",\n",
    "             endpoint=\"https://app.dimensions.ai/api/dsl/v2\")\n",
    "\n",
    "dsl = dimcli.Dsl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\n",
      "0-1000 / 12332 (10.04s)\n",
      "1000-2000 / 12332 (5.32s)\n",
      "2000-3000 / 12332 (4.10s)\n",
      "3000-4000 / 12332 (4.69s)\n",
      "4000-5000 / 12332 (4.85s)\n",
      "5000-6000 / 12332 (6.19s)\n",
      "6000-7000 / 12332 (4.84s)\n",
      "7000-8000 / 12332 (4.53s)\n",
      "8000-9000 / 12332 (4.95s)\n",
      "9000-10000 / 12332 (5.99s)\n",
      "10000-11000 / 12332 (8.05s)\n",
      "11000-12000 / 12332 (3.11s)\n",
      "12000-12332 / 12332 (2.19s)\n",
      "===\n",
      "Records extracted: 12332\n"
     ]
    }
   ],
   "source": [
    "### Extract patent data\n",
    "pat_data = dsl.query_iterative(\"\"\"search patents\n",
    "                                  where publications is not empty and year = 2022                    \n",
    "                                  return patents[id+year+priority_year+cpc+publications+publication_ids]\"\"\") #  limit 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12332, 6)\n",
      "12332\n"
     ]
    }
   ],
   "source": [
    "pat_data_df = pat_data.as_dataframe()\n",
    "print(pat_data_df.shape)\n",
    "print(pat_data_df.id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cpc</th>\n",
       "      <th>priority_year</th>\n",
       "      <th>publication_ids</th>\n",
       "      <th>publications</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>[A61K38/177, A61P29/00, C07K14/70578, A61P37/0...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1027342753, pub.1009940936]</td>\n",
       "      <td>[{'doi': '10.1182/blood-2003-06-2031', 'id': '...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO-2022236333-A2</td>\n",
       "      <td>[A61B3/0016, A61B3/0033]</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1065228315]</td>\n",
       "      <td>[{'doi': '10.1364/ol.35.000739', 'id': 'pub.10...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WO-2022236331-A1</td>\n",
       "      <td>[B05B12/18, B05B12/16, B05B14/00, B05B7/0408]</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1103595211]</td>\n",
       "      <td>[{'doi': '10.1002/adem.201701084', 'id': 'pub....</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO-2022236308-A1</td>\n",
       "      <td>[A61B5/0042, A61B34/30, G01R33/3806, G01R33/34...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1092392383]</td>\n",
       "      <td>[{'doi': '10.1109/tmag.2017.2751001', 'id': 'p...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO-2022236297-A1</td>\n",
       "      <td>[C11D3/48, C11D3/0068, C11D3/381, C11D7/40, C1...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[pub.1080312358]</td>\n",
       "      <td>[{'doi': '10.1128/jb.96.2.479-486.1968', 'id':...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                cpc  \\\n",
       "0  WO-2022236335-A1  [A61K38/177, A61P29/00, C07K14/70578, A61P37/0...   \n",
       "1  WO-2022236333-A2                           [A61B3/0016, A61B3/0033]   \n",
       "2  WO-2022236331-A1      [B05B12/18, B05B12/16, B05B14/00, B05B7/0408]   \n",
       "3  WO-2022236308-A1  [A61B5/0042, A61B34/30, G01R33/3806, G01R33/34...   \n",
       "4  WO-2022236297-A1  [C11D3/48, C11D3/0068, C11D3/381, C11D7/40, C1...   \n",
       "\n",
       "   priority_year                   publication_ids  \\\n",
       "0         2021.0  [pub.1027342753, pub.1009940936]   \n",
       "1         2021.0                  [pub.1065228315]   \n",
       "2         2021.0                  [pub.1103595211]   \n",
       "3         2021.0                  [pub.1092392383]   \n",
       "4         2021.0                  [pub.1080312358]   \n",
       "\n",
       "                                        publications  year  \n",
       "0  [{'doi': '10.1182/blood-2003-06-2031', 'id': '...  2022  \n",
       "1  [{'doi': '10.1364/ol.35.000739', 'id': 'pub.10...  2022  \n",
       "2  [{'doi': '10.1002/adem.201701084', 'id': 'pub....  2022  \n",
       "3  [{'doi': '10.1109/tmag.2017.2751001', 'id': 'p...  2022  \n",
       "4  [{'doi': '10.1128/jb.96.2.479-486.1968', 'id':...  2022  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_data_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+\"2022\"+\".csv\", index=False)\n",
    "pat_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import .csv files\n",
    "# pat_data_df = pd.read_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_01.csv\")\n",
    "\n",
    "# from ast import literal_eval\n",
    "\n",
    "# pat_data_df['publication_ids'] = pat_data_df['publication_ids'].apply(literal_eval) #convert to list type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>publication_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>pub.1027342753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO-2022236335-A1</td>\n",
       "      <td>pub.1009940936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WO-2022236333-A2</td>\n",
       "      <td>pub.1065228315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO-2022236331-A1</td>\n",
       "      <td>pub.1103595211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO-2022236308-A1</td>\n",
       "      <td>pub.1092392383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id publication_ids\n",
       "0  WO-2022236335-A1  pub.1027342753\n",
       "1  WO-2022236335-A1  pub.1009940936\n",
       "2  WO-2022236333-A2  pub.1065228315\n",
       "3  WO-2022236331-A1  pub.1103595211\n",
       "4  WO-2022236308-A1  pub.1092392383"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_pub_df = pat_data_df[['id','publication_ids']]\n",
    "pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "pat_pub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract publication_ids\n",
    "pub_list = pat_pub_df.publication_ids.unique()\n",
    "pd.DataFrame(pub_list, columns=[\"publication_ids\"]).to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+\"2022\"+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Codes for extracting patent data\n",
    "- Maximum 50,000 records\n",
    "- dimcli query cannot recognize ''... so I had to write the loop for each jurisdiction --> fixed\n",
    "- If I could convert dataframe's column into a big list with \"\" as elements, I would use Version 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] \n",
    "offices = ['US','EP','WO']\n",
    "\n",
    "for year in years:\n",
    "    for office in offices:\n",
    "    ### Patent set\n",
    "    query = \"\"\"search patents \n",
    "                where publications is not empty and jurisdiction = \"\"\"+ '''\"'''+office+'''\"''' +\"\"\" and priority_year=\"\"\" + year + \"\"\" \n",
    "                return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "\n",
    "    # Export patent set\n",
    "    pat_df.to_csv(dir+\"pat_data_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "\n",
    "    # Create publication set\n",
    "    pat_pub_df = pat_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    ## Export Publication List version 1. ALL\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "    pub_list.to_csv(dir+\"pub_list_df_\"+year+\"_\"+office+\".csv\", index=False)\n",
    "\n",
    "    ## Export Publication List version 2. 50,000 each\n",
    "    # pub_list = pat_pub_df.publication_ids.unique()\n",
    "    # loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "    # for i in range(1,loop):\n",
    "    #     temp = pub_list.iloc[0:49999,]\n",
    "    #     temp.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\"_US_\"+str(i)+\".csv\")\n",
    "    #     pub_list = pub_list.drop(pub_list.index[0:49999])\n",
    "\n",
    "    ### Publication set\n",
    "    # First record\n",
    "    query = \"\"\"search publications \n",
    "                where id = \"\"\"+'''\"'''+pub_list.publication_ids[0]+'''\"'''+\"\"\"\n",
    "                return publications[id+type+volume+year+issue+title+journal+authors]\"\"\"\n",
    "    temp_data = dsl.query(query)    \n",
    "    pub_df = temp_data.as_dataframe()\n",
    "\n",
    "    for pub in range(1,len(pub_list.publication_ids)):\n",
    "        query = \"\"\"search publications \n",
    "                    where id = \"\"\"+'''\"'''+pub_list.publication_ids[pub]+'''\"'''+\"\"\"\n",
    "                    return publications[id+type+volume+year+issue+title+journal+authors+category_for]\"\"\"\n",
    "        temp_data = dsl.query(query)    \n",
    "        temp_data = temp_data.as_dataframe()\n",
    "        \n",
    "        # bind rows\n",
    "        pub_df = pd.concat([pub_df, temp_data], axis=0)\n",
    "\n",
    "        print(year, office, pub)\n",
    "\n",
    "    # Save publication set\n",
    "    pub_df.to_csv(dir+\"pub_data_df_\"+year+\"_\"+office+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned Patents: 20 (total = 61554)\n",
      "Time: 1.53s\n",
      "Returned Patents: 20 (total = 42638)\n",
      "Time: 1.44s\n",
      "2010\n",
      "Returned Patents: 20 (total = 64011)\n",
      "Time: 6.10s\n",
      "Returned Patents: 20 (total = 42616)\n",
      "Time: 2.79s\n",
      "2011\n",
      "Returned Patents: 20 (total = 65138)\n",
      "Time: 1.40s\n",
      "Returned Patents: 20 (total = 40043)\n",
      "Time: 6.10s\n",
      "2012\n",
      "Returned Patents: 20 (total = 67394)\n",
      "Time: 1.40s\n",
      "Returned Patents: 20 (total = 42498)\n",
      "Time: 4.59s\n",
      "2013\n",
      "Returned Patents: 20 (total = 61421)\n",
      "Time: 6.02s\n",
      "Returned Patents: 20 (total = 39677)\n",
      "Time: 1.43s\n",
      "2014\n",
      "Returned Patents: 20 (total = 57035)\n",
      "Time: 4.63s\n",
      "Returned Patents: 20 (total = 38526)\n",
      "Time: 1.49s\n",
      "2015\n",
      "Returned Patents: 20 (total = 50138)\n",
      "Time: 5.93s\n",
      "Returned Patents: 20 (total = 40015)\n",
      "Time: 6.11s\n",
      "2016\n",
      "Returned Patents: 20 (total = 43624)\n",
      "Time: 5.92s\n",
      "Returned Patents: 20 (total = 42727)\n",
      "Time: 6.05s\n",
      "2017\n",
      "Returned Patents: 20 (total = 30421)\n",
      "Time: 1.42s\n",
      "Returned Patents: 20 (total = 46209)\n",
      "Time: 4.63s\n",
      "2018\n",
      "Returned Patents: 20 (total = 19572)\n",
      "Time: 1.50s\n",
      "Returned Patents: 20 (total = 42038)\n",
      "Time: 5.83s\n",
      "2019\n",
      "Returned Patents: 20 (total = 9903)\n",
      "Time: 1.43s\n",
      "Returned Patents: 20 (total = 47316)\n",
      "Time: 5.32s\n",
      "2020\n",
      "Returned Patents: 20 (total = 1868)\n",
      "Time: 5.47s\n",
      "Returned Patents: 20 (total = 14738)\n",
      "Time: 1.44s\n",
      "2021\n",
      "Returned Patents: 20 (total = 73)\n",
      "Time: 4.59s\n",
      "Returned Patents: 5 (total = 5)\n",
      "Time: 1.44s\n",
      "2022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>USRec</th>\n",
       "      <th>EUWORec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>61554</td>\n",
       "      <td>42638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>64011</td>\n",
       "      <td>42616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>65138</td>\n",
       "      <td>40043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>67394</td>\n",
       "      <td>42498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>61421</td>\n",
       "      <td>39677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>57035</td>\n",
       "      <td>38526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>50138</td>\n",
       "      <td>40015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>43624</td>\n",
       "      <td>42727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>30421</td>\n",
       "      <td>46209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>19572</td>\n",
       "      <td>42038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020</td>\n",
       "      <td>9903</td>\n",
       "      <td>47316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021</td>\n",
       "      <td>1868</td>\n",
       "      <td>14738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  USRec  EUWORec\n",
       "0   2010  61554    42638\n",
       "1   2011  64011    42616\n",
       "2   2012  65138    40043\n",
       "3   2013  67394    42498\n",
       "4   2014  61421    39677\n",
       "5   2015  57035    38526\n",
       "6   2016  50138    40015\n",
       "7   2017  43624    42727\n",
       "8   2018  30421    46209\n",
       "9   2019  19572    42038\n",
       "10  2020   9903    47316\n",
       "11  2021   1868    14738\n",
       "12  2022     73        5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check total counts\n",
    "\n",
    "years = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022'] \n",
    "totalRecUS = []\n",
    "totalRecEU = []\n",
    "totalRecWO = []\n",
    "for year in years:\n",
    "    ### US\n",
    "    query = \"\"\"search patents \n",
    "                    where publications is not empty and jurisdiction in [\"US\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                    return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecUS.append(pat_data.count_total)\n",
    "\n",
    "    ### EP\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and jurisdiction in [\"EP\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "            return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecEUWO.append(pat_data.count_total)\n",
    "\n",
    "    ### WO\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and jurisdiction in [\"WO\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "            return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query(query) \n",
    "    totalRecEUWO.append(pat_data.count_total)\n",
    "\n",
    "    print(year)\n",
    "\n",
    "# Present result\n",
    "pd.DataFrame({'year':years,'USRec':totalRecUS,'EUWORec':totalRecEUWO})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = '2021'\n",
    "\n",
    "for year in years:\n",
    "    query = \"\"\"search patents \n",
    "            where publications is not empty and year=\"\"\" + year + \"\"\"\n",
    "            return patents[id+year+priority_year+cpc+publications+publication_ids]\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "    rangeIndex = int(temp.count_total/1000)+1\n",
    "\n",
    "    for t in range(50,rangeIndex):\n",
    "        query = \"\"\"search patents \n",
    "            where publications is not empty and year=\"\"\" + year + \"\"\"\n",
    "            return patents[id+year+priority_year+cpc+publications+publication_ids+reference_ids+times_cited] limit 1000 skip \"\"\" + str(1000*t)\n",
    "        temp_data = dsl.query(query)\n",
    "        temp_df = temp_data.as_dataframe()\n",
    "        # bind rows\n",
    "        pat_df = pd.concat([pat_df, temp_df], axis=0)\n",
    "        print(t)\n",
    "\n",
    "    # Save patent set\n",
    "    pat_data_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\".csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_data_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pd.DataFrame(pub_list, columns=[\"publication_ids\"]).to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%dslloop is a cell magic, but the cell body is empty. Did you mean the line magic %dslloop (single %)?\n"
     ]
    }
   ],
   "source": [
    "# %%dslloop my_data search publications for \"malaria\" return publications limit 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EP #####\n",
    "    query = \"\"\"search patents \n",
    "                where publications is not empty and jurisdiction in [\"EP\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "\n",
    "    # Save patent set\n",
    "    pat_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\"_EP.csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "\n",
    "    loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "    \n",
    "    for i in range(1,loop):\n",
    "        temp = pub_list.iloc[0:49999,]\n",
    "        temp.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\"_EP_\"+str(i)+\".csv\")\n",
    "        pub_list = pub_list.drop(pub_list.index[0:49999])\n",
    "\n",
    "    ##### WO #####\n",
    "    query = \"\"\"search patents \n",
    "                where publications is not empty and jurisdiction in [\"WO\"] and priority_year=\"\"\" + year + \"\"\" \n",
    "                return patents[id+family_id+priority_year+priority_date+jurisdiction+cpc+publication_ids] sort by priority_date\"\"\"\n",
    "    pat_data = dsl.query_iterative(query) \n",
    "    pat_df = pat_data.as_dataframe()\n",
    "\n",
    "    # Save patent set\n",
    "    pat_df.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pat_data_df_\"+year+\"_WO.csv\", index=False)\n",
    "\n",
    "    # Save publication set\n",
    "    pat_pub_df = pat_df[['id','publication_ids']]\n",
    "    pat_pub_df = pat_pub_df.explode(\"publication_ids\", ignore_index=True)\n",
    "\n",
    "    # Extract publication_ids\n",
    "    pub_list = pat_pub_df.publication_ids.unique()\n",
    "    pub_list = pd.DataFrame(pub_list, columns=[\"publication_ids\"])\n",
    "\n",
    "    loop = math.ceil(pub_list.shape[0]/50000)+1\n",
    "    \n",
    "    for i in range(1,loop):\n",
    "        temp = pub_list.iloc[0:49999,]\n",
    "        temp.to_csv(\"E:/Google Drive (awekim@handong.edu)/[Research]/00_Dimensions/Dimension_files/pub_list_df_\"+year+\"_WO_\"+str(i)+\".csv\")\n",
    "        pub_list = pub_list.drop(pub_list.index[0:49999])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
